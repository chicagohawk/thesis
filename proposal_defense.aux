\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Nomenclatures}{5}}
\citation{reservoir simulation book}
\citation{review of black-box modeling}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{6}}
\newlabel{intro}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Optimization based on gray-box PDE simulation}{6}}
\citation{Buckley Leverett}
\citation{Reservoir Simulation Book}
\citation{Boyd optimization}
\citation{hanmaster}
\citation{Opt Koziel Book}
\citation{gradfreereview}
\citation{dynamicprogramming}
\citation{survey of high dimensional blackbox optimization}
\citation{dimensional reduction}
\citation{decomposition}
\citation{variable selection}
\citation{survey of high dimensional blackbox optimization}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Problem setup}{7}}
\newlabel{psetup}{{2.2}{7}}
\newlabel{first equation}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gradient-free and gradient-based optimization}{7}}
\newlabel{gradfree_gradbased}{{2.3}{7}}
\citation{quasiNewton}
\citation{cont discretize adjoint}
\citation{automaticdiff}
\citation{jones1998}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Proposal outline}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem statement / Thesis objective / Expected contribution / Timeline}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem statement}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Thesis objective}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Expected contribution}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Timeline}{9}}
\citation{Opt Koziel Book}
\citation{Surrogate based analysis and optimization}
\citation{Space mapping 1}
\citation{Opt Koziel Book}
\citation{simplified physics}
\citation{Space mapping 1}
\citation{coarse discretization}
\citation{gradient kriging surrogate}
\citation{poly functional surrogate}
\citation{kriging functional surrogate}
\citation{ann functional surrogate}
\citation{Opt Koziel Book}
\citation{thin airfoil}
\citation{turbulent modeling R low}
\citation{turbulent modeling R high}
\citation{KennedyOhagan1}
\citation{andrewras}
\citation{trustregionwild}
\citation{trustregionconn}
\@writefile{toc}{\contentsline {section}{\numberline {4}Twin model}{10}}
\newlabel{gradient_surrogate}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Review of surrogate methods}{10}}
\newlabel{review surrogate methods}{{4.1}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Envision of twin model}{10}}
\citation{Hamilton Fluid Dynamics}
\citation{NP hard}
\citation{hanmaster}
\citation{numerical schemes for hyperbolic equation review}
\citation{SI old}
\citation{NARMAXbook}
\newlabel{general equation}{{8}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Review of system identification}{11}}
\newlabel{SI review}{{4.3}{11}}
\newlabel{linear dynamic}{{9}{11}}
\citation{NARMAXbook}
\citation{piecewise linear}
\citation{NARMAXbook}
\citation{cross correlation}
\citation{feedback linear}
\citation{NARMAXbook}
\citation{volterra 1}
\citation{volterra 2}
\citation{NARMAXbook}
\citation{volterra 1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces block structure model\relax }}{12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Wiener}{{\caption@xref {Wiener}{ on input line 471}}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces feedback model\relax }}{12}}
\newlabel{Wiener}{{\caption@xref {Wiener}{ on input line 482}}{12}}
\citation{billings 1981}
\citation{NARMAXbook}
\citation{Wavelet SI}
\citation{ANN SI}
\citation{correlation model validation}
\newlabel{polynomial Volterra}{{12}{13}}
\citation{hanmaster}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Formulation of twin model with fixed structure}{14}}
\newlabel{general formulation}{{4.4}{14}}
\newlabel{minimizer false}{{14}{14}}
\newlabel{minimizer twin model}{{15}{14}}
\newlabel{minimizer twin model discrete}{{16}{14}}
\newlabel{minimizer twin model discrete mapping}{{17}{14}}
\newlabel{objective twin model}{{18}{14}}
\newlabel{first equation 2}{{19}{14}}
\citation{adjoint}
\citation{cont discretize adjoint}
\citation{wavelet mallat}
\newlabel{objective twin model steady}{{20}{15}}
\newlabel{first equation 2 steady}{{21}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Adjoint-based parameter estimation of twin model}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Basis library for twin model}{15}}
\newlabel{basis selection}{{4.6}{15}}
\citation{haar}
\citation{Analytic Meyer}
\citation{Buckley Leverett}
\newlabel{scaling projection}{{28}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Meyer wavelet scaling function and its spectrum\relax }}{16}}
\newlabel{fig:Meyer}{{\caption@xref {fig:Meyer}{ on input line 804}}{16}}
\citation{wavelet mallat}
\citation{Dijkema book}
\newlabel{basis flux wavelet}{{31}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces $\mathaccentV {bar}016{\phi }_{0,0}$ in 1D and 2D, integrated from Meyer wavelet scaling function\relax }}{17}}
\newlabel{fig:Meyer Basis}{{4}{17}}
\newlabel{phijk}{{33}{17}}
\newlabel{phirk}{{34}{17}}
\citation{Buckley Leverett}
\citation{numpad}
\citation{Quasi-Newton Review}
\citation{nlopt}
\citation{LBFGS}
\citation{Eric master thesis}
\citation{nlopt}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces $\qopname  \relax o{tanh}$ sigmoid function in 1D and 2D\relax }}{18}}
\newlabel{fig:sigmoid basis}{{5}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Numerical example: twin model with fixed structure}{18}}
\newlabel{fixed numerical example}{{4.7}{18}}
\newlabel{BL eqn}{{35}{18}}
\newlabel{BL flux}{{38}{18}}
\newlabel{twin model 3}{{39}{18}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Progressive optimization procedure\relax }}{19}}
\newlabel{progressive algo}{{1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Initial condition $u_0(x)$\relax }}{19}}
\newlabel{fig:initial condition}{{6}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Compare $F(u)$ and $\frac  {dF}{du}$ with $\mathaccentV {tilde}07E{F}(u)$ and $\frac  {d\mathaccentV {tilde}07E{F}}{du}$\relax }}{20}}
\newlabel{fig:flux compare}{{7}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Compare $u(t,x)$ with $\mathaccentV {tilde}07E{u}(t,x)$\relax }}{20}}
\newlabel{fig:sol compare}{{8}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Compare $F(u)$ and $\frac  {dF}{du}$ with $\mathaccentV {tilde}07E{F}(u)$ and $\frac  {d\mathaccentV {tilde}07E{F}}{du}$ with higher flux resolution\relax }}{20}}
\newlabel{fig:flux compare 30}{{9}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Compare $u(t,x)$ with $\mathaccentV {tilde}07E{u}(t,x)$ with higher flux resolution\relax }}{21}}
\newlabel{fig:sol compare 30}{{10}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Twin model with adaptive structure}{21}}
\newlabel{adaptive}{{4.8}{21}}
\newlabel{twin equation def}{{40}{21}}
\newlabel{global error}{{41}{22}}
\newlabel{local error}{{42}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces illustration of twin model with restart.\relax }}{22}}
\newlabel{fig:tmodelrestart}{{11}{22}}
\newlabel{theorem: 1}{{1}{22}}
\citation{NARMAXbook}
\citation{Lasso variable selection}
\citation{Billing feature selection}
\citation{review dimensional reduction}
\citation{PCA review}
\citation{NARMAXbook}
\citation{Critical review of variable selection}
\citation{stepwise variable selection}
\citation{Critical review of variable selection}
\citation{Billing feature selection}
\citation{Critical review of variable selection}
\newlabel{linear eqn}{{47}{23}}
\newlabel{linear selection}{{50}{23}}
\newlabel{selected variable model}{{53}{23}}
\citation{AIC}
\citation{BIC}
\citation{Lasso variable selection}
\citation{sklearn}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Basis selection using Lasso. The figure on the right side shows the primal model's solution $u(t,x)$. The figure on the left side shows all candidate bases. The selected bases are colored red. Notice how the selected bases correspond to the colorbar of the primal model solution.\relax }}{25}}
\newlabel{fig:basis_selection_1}{{12}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Basis selection with a different $u(t,x)$. Notice how selected bases depend on the primal model solution.\relax }}{25}}
\newlabel{fig:basis_selection_2}{{13}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Future work}{25}}
\citation{LES}
\citation{LES oldest}
\citation{DNS}
\citation{constraint lift}
\citation{MFO: two stage}
\citation{Pattern Search Convergence}
\citation{Pattern Search Convergence MFO}
\@writefile{toc}{\contentsline {section}{\numberline {5}Optimization with twin model}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivation of the Bayesian approach}{27}}
\newlabel{general opt}{{56}{27}}
\citation{inexactgradient1}
\citation{jones1998}
\citation{trustregionconn}
\citation{trustregionwild}
\citation{simplified physics}
\citation{coarse discretization}
\citation{andrewras}
\citation{andrew thesis}
\citation{trustregionconn}
\citation{andrew thesis}
\citation{Krigingold}
\citation{kriging}
\citation{Mockus Bayesian opt}
\citation{practicalBayesianopt}
\citation{Bayopt converge 2}
\citation{convergenceBayesian}
\citation{KennedyOhagan2}
\citation{KennedyOhagan1}
\citation{KennedyOhagan2}
\citation{RKHS aronszajn}
\citation{practicalBayesianopt}
\citation{cokriging}
\newlabel{ohagan_assumption}{{57}{28}}
\newlabel{joint distribution}{{59}{28}}
\citation{adjoint gradient cokriging without MLE}
\citation{gradient kriging surrogate}
\citation{practicalBayesianopt}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Train the twin model at $c=0$, the resultant twin model gives good approximation for the $\frac  {dJ}{dc}$.\relax }}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bayesian modeling of the primal and twin models}{30}}
\newlabel{bayesian_model}{{5.2}{30}}
\newlabel{base Bayes model}{{61}{30}}
\newlabel{funkernel}{{66}{30}}
\citation{practicalBayesianopt}
\citation{practicalBayesianopt}
\newlabel{noise kernel}{{69}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Optimization using the posterior of the objective function}{31}}
\newlabel{bayesian_opt}{{5.3}{31}}
\newlabel{EI form}{{73}{31}}
\citation{MCMC hyperparameters}
\citation{practicalBayesianopt}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The flowchart of Bayesian optimization with twin model.\relax }}{33}}
\newlabel{fig: Bopt flow}{{15}{33}}
\citation{Torn and Zilinskas}
\citation{convergenceBayesian}
\citation{Bayopt converge 2}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Minimizing $J(x) = \DOTSB \sum@ \slimits@ _{i=1}^{\textrm  {dim}}x_i^2$ with variable $\textrm  {dim}$. The y-axis is the best / smallest $J$ after 10 function evaluations, in log 10 scale. The blue line is obtained from Bayesian optimization with no gradient information. The green line is obtained from Bayesian optimization with a noisy gradient, by setting $\sigma ^2 = \sigma ^2_\epsilon $, see Eqn\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 66\hbox {}\unskip \@@italiccorr )}} and Eqn\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 69\hbox {}\unskip \@@italiccorr )}}. The red line is obtained from Bayesian optimization with a less noisy gradient, by setting $0.1 \sigma ^2 = \sigma ^2_\epsilon $ We use Monte Carlo to randomly select some initial guesses for $x$. Each point on these lines represents the averaged $J_{10}$ using a random set of initial guesses.\relax }}{34}}
\newlabel{fig: dim and J}{{16}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Discussion of the convergence property}{34}}
\citation{ubend rans opt 1}
\citation{ubend rans opt 2}
\newlabel{theorem: 2}{{3}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Optimization constraints}{35}}
\newlabel{constraints}{{5.5}{35}}
\citation{nlopt}
\citation{constraint Bayesian Opt}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Example of a constraint of the feasible geometry, The brighter region indicates feasible region of the return bend geometry. The wireframe indicates a feasible design.\relax }}{36}}
\newlabel{fig: simple constraint}{{17}{36}}
\newlabel{EI form constraint}{{76}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The flowchart of constraint Bayesian optimization with twin model.\relax }}{37}}
\newlabel{fig: constraint bay opt}{{18}{37}}
\citation{ubend rans opt 1}
\citation{ubend rans opt 2}
\citation{ubend rans opt 2}
\citation{ubend rans opt 1}
\@writefile{toc}{\contentsline {section}{\numberline {6}Application to a turbulent flow optimization}{38}}
\newlabel{examples}{{6}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Problem description}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Example of turbine blade cooling tubes. \emph  {Image from: http://www.amateras-tyo.biz/eng/technologies.html}\relax }}{38}}
\newlabel{fig: ubend picture}{{19}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Review of incompressible RANS models}{38}}
\citation{Wilcox CFD}
\citation{Wilcox CFD}
\citation{Wilcox CFD}
\citation{Wilcox CFD}
\citation{Wilcox CFD}
\citation{ubend rans opt 1}
\citation{ubend rans opt 2}
\newlabel{Prandtl mixing length}{{80}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Future work}{39}}
\@writefile{toc}{\contentsline {section}{Appendices}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proof of theorem 1\hbox {}: global-local error}{41}}
\newlabel{appendix 1}{{A}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Trajectories of the primal model and the twin model. $H$ and $G$ are their timestep-wise mapping functions.\relax }}{41}}
\newlabel{fig:sketch}{{20}{41}}
\newlabel{global error}{{87}{41}}
\newlabel{local error}{{88}{41}}
\newlabel{expansion global error}{{90}{41}}
\bibcite{hanmaster}{1}
\bibcite{andrewras}{2}
\bibcite{jones1998}{3}
\bibcite{convergenceBayesian}{4}
\bibcite{NARMAXbook}{5}
\bibcite{practicalBayesianopt}{6}
\newlabel{error diff}{{91}{42}}
\newlabel{error diff}{{94}{42}}
\newlabel{error diff 2}{{95}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Proof of theorem 3\hbox {}: design sequence is dense}{42}}
\newlabel{proof convergence append}{{B}{42}}
\bibcite{KennedyOhagan1}{7}
\bibcite{KennedyOhagan2}{8}
\bibcite{MCMC hyperparameters}{9}
\bibcite{Krigingold}{10}
\bibcite{inexactgradient1}{11}
\bibcite{inexactnewton1}{12}
\bibcite{trustregionconn}{13}
\bibcite{trustregionwild}{14}
\bibcite{kriging}{15}
\bibcite{cokriging}{16}
\bibcite{bishopbook}{17}
\bibcite{SarmaEKF}{18}
\bibcite{gradfreereview}{19}
\bibcite{dynamicprogramming}{20}
\bibcite{quasiNewton}{21}
\bibcite{adjoint}{22}
\bibcite{cont discretize adjoint}{23}
\bibcite{automaticdiff}{24}
\bibcite{reservoir simulation book}{25}
\bibcite{wavelet mallat}{26}
\bibcite{Bayopt converge 2}{27}
\bibcite{Buckley Leverett}{28}
\bibcite{Reservoir Simulation Book}{29}
\bibcite{Boyd optimization}{30}
\bibcite{Sigmoid Approximation}{31}
\bibcite{haar}{32}
\bibcite{Analytic Meyer}{33}
\bibcite{Opt Koziel Book}{34}
\bibcite{Surrogate based analysis and optimization}{35}
\bibcite{Space mapping 1}{36}
\bibcite{Space mapping 2}{37}
\bibcite{simplified physics}{38}
\bibcite{coarse discretization}{39}
\bibcite{gradient kriging surrogate}{40}
\bibcite{poly functional surrogate}{41}
\bibcite{kriging functional surrogate}{42}
\bibcite{ann functional surrogate}{43}
\bibcite{adjoint gradient cokriging without MLE}{44}
\bibcite{survey of high dimensional blackbox optimization}{45}
\bibcite{review of black-box modeling}{46}
\bibcite{dimensional reduction}{47}
\bibcite{decomposition}{48}
\bibcite{variable selection}{49}
\bibcite{thin airfoil}{50}
\bibcite{turbulent modeling R high}{51}
\bibcite{turbulent modeling R low}{52}
\bibcite{NP hard}{53}
\bibcite{Hamilton Fluid Dynamics}{54}
\bibcite{numerical schemes for hyperbolic equation review}{55}
\bibcite{SI old}{56}
\bibcite{piecewise linear}{57}
\bibcite{volterra 1}{58}
\bibcite{volterra 2}{59}
\bibcite{cross correlation}{60}
\bibcite{feedback linear}{61}
\bibcite{billings 1981}{62}
\bibcite{ANN SI}{63}
\bibcite{Wavelet SI}{64}
\bibcite{correlation model validation}{65}
\bibcite{Dijkema book}{66}
\bibcite{simple opt}{67}
\bibcite{numpad}{68}
\bibcite{sklearn}{69}
\bibcite{nlopt}{70}
\bibcite{Quasi-Newton Review}{71}
\bibcite{Eric master thesis}{72}
\bibcite{LBFGS}{73}
\bibcite{review dimensional reduction}{74}
\bibcite{review variable selection}{75}
\bibcite{Billing feature selection}{76}
\bibcite{PCA review}{77}
\bibcite{constraint Bayesian Opt}{78}
\bibcite{Lasso variable selection}{79}
\bibcite{Critical review of variable selection}{80}
\bibcite{stepwise variable selection}{81}
\bibcite{Elastic net variable selection}{82}
\bibcite{AIC}{83}
\bibcite{BIC}{84}
\bibcite{Mockus Bayesian opt}{85}
\bibcite{MFO: two stage}{86}
\bibcite{MFO: bayesian discrepancy aerodynamics}{87}
\bibcite{MFO: trust region acdl}{88}
\bibcite{Pattern Search Convergence}{89}
\bibcite{Pattern Search Convergence MFO}{90}
\bibcite{andrew thesis}{91}
\bibcite{RKHS aronszajn}{92}
\bibcite{LES}{93}
\bibcite{LES oldest}{94}
\bibcite{DNS}{95}
\bibcite{constraint lift}{96}
\bibcite{ubend rans opt 1}{97}
\bibcite{ubend rans opt 2}{98}
\bibcite{Wilcox CFD}{99}
\bibcite{Torn and Zilinskas}{100}
